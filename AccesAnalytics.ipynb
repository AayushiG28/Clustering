{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gower\n",
    "from pyclustering.cluster.kmedoids import kmedoids\n",
    "from pyclustering.cluster import cluster_visualizer\n",
    "from pyclustering.utils import read_sample\n",
    "from pyclustering.samples.definitions import FCPS_SAMPLES\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess(path,filename):\n",
    "    \n",
    "    filepath=path\n",
    "    fileName=filename\n",
    "    train_df = pd.read_csv(fileName)\n",
    "    #print(train_Df)\n",
    "    #http://localhost:8888/notebooks/Untitled15.ipynb#\n",
    "        \n",
    "    train_df.drop('RESOURCE', axis=1, inplace=True)\n",
    "    train_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    " \n",
    "\n",
    "    col_names = list(train_df)\n",
    "\n",
    "    for col in col_names:\n",
    "        if(col!=\"RESOURCE\"):\n",
    "            train_df[col] = train_df[col].astype('category',copy=False)\n",
    "    \n",
    "    print(train_df.shape)\n",
    "    return train_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dismlrty_matrix(train_df):\n",
    "    \n",
    "    X = np.asarray(train_df)\n",
    "\n",
    "    print(\"Getting the dissimilarity matrix from the gower distance\") \n",
    "    matrix=gower.gower_matrix(X)\n",
    "    print(\"Dissimilarity matrix Built ðŸ˜Š\") \n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_medoids(matrix,initial_medoids):\n",
    "    kmedoids_instance = kmedoids(matrix, initial_medoids, data_type='distance_matrix')\n",
    "    kmedoids_instance.process()\n",
    "    clusters = kmedoids_instance.get_clusters()\n",
    "    medoids = kmedoids_instance.get_medoids()\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_label(cluster,num_clust,matrix):\n",
    "    lst4=[]\n",
    "    x=num_clust\n",
    "    if x==3:\n",
    "        x1=cluster[0]\n",
    "        x2=cluster[1]\n",
    "        x3=cluster[2]\n",
    "    \n",
    "        for i,x in enumerate(matrix):\n",
    "            if i in x1:\n",
    "                lst4.append(0)\n",
    "            elif i in x2:\n",
    "                lst4.append(1)\n",
    "            else:\n",
    "                lst4.append(2) \n",
    "        \n",
    "    elif x==4:\n",
    "        x1=cluster[0]\n",
    "        x2=cluster[1]\n",
    "        x3=cluster[2]\n",
    "        x4=cluster[3]\n",
    "    \n",
    "        for i,x in enumerate(matrix):\n",
    "            if i in x1:\n",
    "                lst4.append(0)\n",
    "            elif i in x2:\n",
    "                lst4.append(1)\n",
    "            elif i in x3:\n",
    "                lst4.append(2)\n",
    "            else:\n",
    "                lst4.append(3) \n",
    "            \n",
    "    elif x==5:\n",
    "        x1=cluster[0]\n",
    "        x2=cluster[1]\n",
    "        x3=cluster[2]\n",
    "        x4=cluster[3]\n",
    "        x5=cluster[4]\n",
    "    \n",
    "        for i,x in enumerate(matrix):\n",
    "            if i in x1:\n",
    "                lst4.append(0)\n",
    "            elif i in x2:\n",
    "                lst4.append(1)\n",
    "            elif i in x3:\n",
    "                lst4.append(2)            \n",
    "            elif i in x4:\n",
    "                lst4.append(3)\n",
    "            else:\n",
    "                lst4.append(4)\n",
    "    return lst4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_cluster(train_df,matrix,num_clust):\n",
    "    \n",
    "    \n",
    "    silhouet_new=[]\n",
    "    # finding initial medioids frpm multiple iterations\n",
    "    for iteration in range(5):\n",
    "        silhouet=[]\n",
    "        n_clusters=num_clust\n",
    "        row1 = train_df.sample(n = num_clust) \n",
    "        initial_medoids=[]\n",
    "        for i in row1.index:\n",
    "            initial_medoids.append(i)\n",
    "        \n",
    "        print(\"no of iteration id\",iteration)\n",
    "        #print(initial_medoids)\n",
    "        silhouet.append(initial_medoids)\n",
    "        # calling the clustering function to perform clustering on the dissimilarity matrix\n",
    "        \n",
    "        clusters=cluster_medoids(matrix,initial_medoids)\n",
    "        \n",
    "        # labelling of clusters\n",
    "        \n",
    "        labels= cluster_label(clusters,num_clust,matrix)\n",
    "        \n",
    "        \n",
    "        #calculating silhouette_score        \n",
    "        silhouette_avg=silhouette_score(matrix,labels,metric='precomputed')\n",
    "        \n",
    "        \n",
    "        silhouet.append(silhouette_avg)\n",
    "        silhouet.append(labels)\n",
    "        \n",
    "        #print(silhouet)\n",
    "        \n",
    "        if len(silhouet_new)==0:\n",
    "            silhouet_new.append(silhouet)\n",
    "            print(\"true\")\n",
    "        else:\n",
    "            if silhouet[1]>silhouet_new[0][1]:\n",
    "                silhouet_new.clear()\n",
    "                silhouet_new.append(silhouet)\n",
    "                #print(\"false\")\n",
    "            \n",
    "            else:\n",
    "                print(\"True1\")\n",
    "                \n",
    "        #print(silhouet_new)\n",
    "        #silhouet.clear()  \n",
    "        \n",
    "        \n",
    "    return silhouet_new\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "  \n",
    "\n",
    "  \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_graph(silh_score,matrix,train_Df,n_clusters):\n",
    "    \n",
    "    #print(silh_score)\n",
    "    label=silh_score[0][2]\n",
    "    sample_silhouette_values = silhouette_samples(matrix, label)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    \n",
    "    ax1.set_ylim([0, len(train_Df) + (n_clusters + 1) * 10])\n",
    "    \n",
    "    cluster_new = np.asarray(label)\n",
    "    \n",
    "    silhouette_avg=silh_score[0][1]\n",
    "    \n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        #print(i)\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_new == i]\n",
    "        \n",
    "        #print(ith_cluster_silhouette_values)\n",
    "        \n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    \n",
    "    \n",
    "\n",
    "plt.show()\n",
    "plt.savefig('sil_graph.png')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train=preprocess(r\"C:\\Users\\1185833\\Downloads\",\"valid.csv\")\n",
    "    #print(train)\n",
    "    \n",
    "    matrix=dismlrty_matrix(train)\n",
    "    \n",
    "    print(\"..........\")\n",
    "    \n",
    "    print(\"clustering the data......\")\n",
    "    silh_score=best_cluster(train,matrix,3)\n",
    "    \n",
    "    silhouette_graph(silh_score,matrix,train,3)\n",
    "    \n",
    "    return silh_score,matrix,train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclustering.cluster.rock import rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd C:\\Users\\1185833\\Downloads\\amazon-employee-access-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df.drop(\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df.drop(\"RESOURCE\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=np.array(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rock_instance = rock(train_df,1.0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rock_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " rock_instance.process()\n",
    " \n",
    "# Obtain results of clustering.\n",
    "#clusters = rock_instance.get_clusters()\n",
    " \n",
    "# Visualize clustering results.\n",
    "#visualizer = cluster_visualizer()\n",
    "#visualizer.append_clusters(clusters, sample)\n",
    "#visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = rock_instance.get_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclustering.cluster import cluster_visualizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
